# Integrating Domain Knowledge into Transformer-based Approaches to Vulnerability Detection

TransVulDet is a Transformer-based Language Model for Vulnerability Detection aiming to better domain knowledge interation (e.g. CWE hierarchy) with source code datasets.

### Dataset
* Multiclass Vulnerability Dataset (MVD)
  * 40 CWEs, multiclass
  * https://github.com/muVulDeePecker/muVulDeePecker
* Big-Vul dataset
  * 91 CWE, small
  * https://dl.acm.org/doi/10.1145/3379597.3387501 
* CVEfixes Dataset
  * 209 CWEs
  * https://zenodo.org/record/7029359

### Model
Pre-trained Transformer-based Language Models
* CodeBERT
* GraphCodeBERT
* BERT-based (BERT, RoBERTa, DistillBERT, etc)
* T5

### Evaluation

### Result
